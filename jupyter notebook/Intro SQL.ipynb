{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preface\n**The in troduce in this jupyter notebook is the lecture of kaggle. And I have summaried the lession on kaggle to give you a more general look.**\n\n**Instead of instructing invidual modules, I will use all five syntax on one dataset. Besides, the command's I'm about to write are just animated and don't necessarily solve a specific problem**\n\n**This is my first instructure that I use english, so it have some wrong about grammar. I hope you contributed to this article on everything that did not work well.**"},{"metadata":{},"cell_type":"markdown","source":"**In this section we will learn 5 syntax usualy use in SQL**\n1. SELECT, FROM, WHERE\n2. GROUP BY, HAVING and COUNT\n3. ORDER BY\n4. AS & WITH\n5. JOIN\n\nTo clarify these issues. I'll use all syntax below in one dataset for give you the best overview about five common syntax\n\nI will use the stackoverflow data"},{"metadata":{},"cell_type":"markdown","source":"**First I will clarify the tructure of the dataset in bigquery before we go to dataset and query it. You should look the diagram below or going to the link:** https://www.kaggle.com/dansbecker/getting-started-with-sql-and-bigquery\n\n![](https://i.imgur.com/VQ6nS9r.png)\n\n1. with client in this diagram you have to create and use that client for query dataset in bigquery. client is the first class.\n2. The bigquery-public-data is a common project which contains a lot of small project. Each organization will create for themself such a large project. the \"bigquery-public-data\" is the name of project kaggle created.\n3. \"hacker_news\" is the of many small dataset of kaggle. In this tutorial I will use the stackoverfow project.\n4. The last layer is the real-data that we want to access. All datas are stored in many table with different meanings. There is one or more tables in this last class. \n\n**In summary, if we want to query data from bigquery, we need to do the following steps below:**\n1. create a your client for query the next class\n2. we have to know the name of the sencond class. that name will be provided by the organization. in this tutorial we will use the project kaggle with name is bigquery-public-data.\n3. we also know the name of small project, it just like step above we will be provided by organization. In this tutorial we will use the \"stackoverflow\" project.\n4. After we sucessful three steps above. this is time where we will use five syntax to query data to solve any problem.","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"# the code throwing from 1 to 3 step\n\n# call library bigquery\nfrom google.cloud import bigquery\n\n# create your client()\nclient = bigquery.Client()\n\n# get data referent : that you can not edit in this data referent\ndata_ref = client.dataset(\"stackoverflow\", project = \"bigquery-public-data\")\nprint(data_ref)\n\n# get data that you can edit\ndata = client.get_dataset(data_ref)\nprint(data)\n# data is stackoverfow class that you can edit","execution_count":3,"outputs":[{"output_type":"stream","text":"Using Kaggle's public dataset BigQuery integration.\nDatasetReference('bigquery-public-data', 'stackoverflow')\nDataset(DatasetReference('bigquery-public-data', 'stackoverflow'))\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# but how many table in the small project \"stackoverflow\"\ntables = list(client.list_tables(data_ref))\nlist_tables = [table.table_id for table in tables]\nprint(list_tables)\n# the numbers table of stackoverflow project\nprint(\"the numbers table of stackoverflow project: \",len(list_tables))","execution_count":8,"outputs":[{"output_type":"stream","text":"['badges', 'comments', 'post_history', 'post_links', 'posts_answers', 'posts_moderator_nomination', 'posts_orphaned_tag_wiki', 'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', 'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', 'tags', 'users', 'votes']\nthe numbers table of stackoverflow project:  16\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 1. SELECT, FROM and WHERE\n\nSELECT, FROM and WHERE are important syntax in SQL that you will use it in most queries\n\n**SELECT ... FROM WHERE** :`SELECT` the columns you want to show and process it. `FROM` is the resource of the columns and `WHERE` to choose option for limit data. In the stackoverflow project have table `users`\n\n    Task 1: Show table `users` into dataframe\n    Task 2: Display `display_name` and `age` WHERE location = Israel columns use SELECT FROM WHERE. \n        Note limit data 1GB\n","attachments":{}},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Task 1: show table `users` into dataframe\n    # get table\n    table_users_ref = data_ref.table(\"users\") \n    table_users = client.get_table(table_users_ref)\n    table_users_frame = client.list_rows(table_users, max_results=5).to_dataframe()\n    print(table_users_frame.shape)\n    table_users_frame.head()\n    ","execution_count":13,"outputs":[{"output_type":"stream","text":"(5, 13)\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"    id display_name                                           about_me   age  \\\n0  212   Mike Polen  <p>Christian, dynamic systems engineer, develo...  None   \n1  278    Lea Cohen  <p>Web developer, both server-side and client-...  None   \n2  380      Vaibhav                                               None  None   \n3  527        ggasp  <p>I'll upvote every answer to my questions!</...  None   \n4  889       Eldila  <p>I'm a programmer, scientist, and mathematic...  None   \n\n                     creation_date                 last_access_date  \\\n0 2008-08-03 14:59:56.407000+00:00 2019-08-23 16:10:12.707000+00:00   \n1 2008-08-04 11:28:54.023000+00:00 2019-09-01 04:48:44.660000+00:00   \n2 2008-08-05 10:39:18.677000+00:00 2019-07-29 11:59:18.740000+00:00   \n3 2008-08-06 14:44:09.103000+00:00 2019-08-21 08:38:01.943000+00:00   \n4 2008-08-10 08:04:03.333000+00:00 2017-02-12 01:45:10.563000+00:00   \n\n            location  reputation  up_votes  down_votes  views  \\\n0       Richmond, VA        3421       465           4   1181   \n1             Israel        4261      3470          24    997   \n2     Gurgaon, India        8825       430          46   1218   \n3              Chile         917       135           4    168   \n4  Vancouver, Canada        7208       130           5    461   \n\n  profile_image_url                      website_url  \n0              None          http://about.me/mwpolen  \n1              None  http://leketshibolim.ort.org.il  \n2              None          http://blog.gadodia.net  \n3              None     http://gasparolo.com/gabriel  \n4              None               http://jkwiens.com  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>display_name</th>\n      <th>about_me</th>\n      <th>age</th>\n      <th>creation_date</th>\n      <th>last_access_date</th>\n      <th>location</th>\n      <th>reputation</th>\n      <th>up_votes</th>\n      <th>down_votes</th>\n      <th>views</th>\n      <th>profile_image_url</th>\n      <th>website_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>212</td>\n      <td>Mike Polen</td>\n      <td>&lt;p&gt;Christian, dynamic systems engineer, develo...</td>\n      <td>None</td>\n      <td>2008-08-03 14:59:56.407000+00:00</td>\n      <td>2019-08-23 16:10:12.707000+00:00</td>\n      <td>Richmond, VA</td>\n      <td>3421</td>\n      <td>465</td>\n      <td>4</td>\n      <td>1181</td>\n      <td>None</td>\n      <td>http://about.me/mwpolen</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>278</td>\n      <td>Lea Cohen</td>\n      <td>&lt;p&gt;Web developer, both server-side and client-...</td>\n      <td>None</td>\n      <td>2008-08-04 11:28:54.023000+00:00</td>\n      <td>2019-09-01 04:48:44.660000+00:00</td>\n      <td>Israel</td>\n      <td>4261</td>\n      <td>3470</td>\n      <td>24</td>\n      <td>997</td>\n      <td>None</td>\n      <td>http://leketshibolim.ort.org.il</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>380</td>\n      <td>Vaibhav</td>\n      <td>None</td>\n      <td>None</td>\n      <td>2008-08-05 10:39:18.677000+00:00</td>\n      <td>2019-07-29 11:59:18.740000+00:00</td>\n      <td>Gurgaon, India</td>\n      <td>8825</td>\n      <td>430</td>\n      <td>46</td>\n      <td>1218</td>\n      <td>None</td>\n      <td>http://blog.gadodia.net</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>527</td>\n      <td>ggasp</td>\n      <td>&lt;p&gt;I'll upvote every answer to my questions!&lt;/...</td>\n      <td>None</td>\n      <td>2008-08-06 14:44:09.103000+00:00</td>\n      <td>2019-08-21 08:38:01.943000+00:00</td>\n      <td>Chile</td>\n      <td>917</td>\n      <td>135</td>\n      <td>4</td>\n      <td>168</td>\n      <td>None</td>\n      <td>http://gasparolo.com/gabriel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>889</td>\n      <td>Eldila</td>\n      <td>&lt;p&gt;I'm a programmer, scientist, and mathematic...</td>\n      <td>None</td>\n      <td>2008-08-10 08:04:03.333000+00:00</td>\n      <td>2017-02-12 01:45:10.563000+00:00</td>\n      <td>Vancouver, Canada</td>\n      <td>7208</td>\n      <td>130</td>\n      <td>5</td>\n      <td>461</td>\n      <td>None</td>\n      <td>http://jkwiens.com</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The table has 13 columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Task 2: Display `display_name` and `age` WHERE location = \"Israel\" columns use SELECT FROM WHERE. \n            #Note limit data 1GB\nquery_task2 = \"\"\"\n            SELECT display_name, age\n            FROM `bigquery-public-data.stackoverflow.users`\n            WHERE location = \"Israel\"\n            \"\"\"\nsafe_config_task2 = bigquery.QueryJobConfig(maximun_bytes_billed = 10*10)\nusers_query_job = client.query(query_task2, job_config=safe_config_task2)\nusers_result = users_query_job.to_dataframe()\nusers_result.head()\n","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"  display_name   age\n0    Tal Weiss  None\n1     Ron Sher  None\n2      agoldis  None\n3         numa  None\n4     Sandman4  None","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>display_name</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tal Weiss</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ron Sher</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>agoldis</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>numa</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sandman4</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# 2. GROUP BY, HAVING AND COUNT()\n\n**GROUP BY**: Return the results base on the columns that you grouped. It is may  one or more columns.\n\n**HAVING**: is certain criteria to limit data. HAVING is used in combination with `GROUP BY` .\n\n**COUNT()**: is aggregate function(SUM(),AVG(),MIN(),MAX(),...). COUNT() return the number of entries in the column that you were choosed.\n\n\n    Task 3: show the location column and count how many user in each location. \n            with the number of user more than 10000 \n            limit data 1GB"},{"metadata":{"trusted":true},"cell_type":"code","source":"#    Task 3: show the location column and count how many user in each location. \n#             with the number of user more than 5 \n#             limit data 1GB\nquery_task3 = \"\"\"\n            SELECT location,COUNT(1) AS NUM_USERS\n            FROM `bigquery-public-data.stackoverflow.users`\n            GROUP BY location\n            HAVING COUNT(1) > 10000 \n            \"\"\"\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job = client.query(query_task3, job_config=dry_run_config)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job.total_bytes_processed))\n\nsafe_config_task3 = bigquery.QueryJobConfig(maximun_bytes_billed = 10*10)\nusers_query_task3_job = client.query(query_task3, job_config = safe_config_task3)\nusers_task3_result = users_query_task3_job.to_dataframe()\nprint(users_task3_result)","execution_count":39,"outputs":[{"output_type":"stream","text":"This query will process 54537655 bytes.\n                       location  NUM_USERS\n0                 United States      18527\n1                          None    8147085\n2        London, United Kingdom      19696\n3                   Netherlands      12304\n4                        Russia      12051\n5                        Canada      12756\n6                        Brazil      11389\n7                United Kingdom      13605\n8                       Germany      31225\n9                        Israel      12676\n10                    Singapore      13100\n11                 Delhi, India      13315\n12                        India      63774\n13                       Poland      10523\n14             Bangalore, India      10245\n15                Paris, France      16643\n16                  Philippines      15263\n17                        China      23335\n18                         Iran      10740\n19                    Indonesia      14374\n20   Chennai, Tamil Nadu, India      24606\n21                       France      18544\n22                        Egypt      11572\n23                          USA      16215\n24  Bangalore, Karnataka, India      48424\n25     Pune, Maharashtra, India      26896\n26                     Pakistan      12283\n27          Toronto, ON, Canada      10736\n28    Ahmedabad, Gujarat, India      11065\n29  Bengaluru, Karnataka, India      15676\n30   Mumbai, Maharashtra, India      17546\n31  Hyderabad, Telangana, India      28157\n32                   London, UK      11321\n33            Dhaka, Bangladesh      10474\n34      New Delhi, Delhi, India      10206\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 3. ORDER BY\n**ORDER BY**: is usually the last clause in your query. And it sorts the results returned by the rest of your query.\n\n**DATE** There are two type of time DATE(`YYYY-[M]M-[D]D`) and DATETIME(  like this `2019-08-23 16:10:12.707000+00:00`)  \n\n**EXTRACT**: If you want to query datatime of any coumns you can use EXTRACT function. \n            Example: `EXTRACT([YEAR/MONTH/WEEK/DAY/HOUR/SECOND/SEC] from [the name column])`\n            \n    Task 4: like task 3. but add some mission\n            - sort base on location decrease"},{"metadata":{"trusted":true},"cell_type":"code","source":"##     Task 4: like task 3. but add some mission\n#             - sort base on location decrease\n\nquery_task4 = \"\"\"\n              SELECT location,COUNT(1) AS num_users\n              FROM `bigquery-public-data.stackoverflow.users`\n              GROUP BY location\n              HAVING COUNT(1) >10000\n              ORDER BY COUNT(1) DESC        \n              \"\"\"\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config4 = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job4 = client.query(query_task4, job_config=dry_run_config4)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job4.total_bytes_processed))\n\nsafe_config_task4 = bigquery.QueryJobConfig(maximun_bytes_billed = 10*10)\nusers_query_task4_job = client.query(query_task4, job_config = safe_config_task4)\nusers_task4_result = users_query_task4_job.to_dataframe()\nprint(users_task4_result)","execution_count":69,"outputs":[{"output_type":"stream","text":"This query will process 54537655 bytes.\n                       location  num_users\n0                          None    8147085\n1                         India      63774\n2   Bangalore, Karnataka, India      48424\n3                       Germany      31225\n4   Hyderabad, Telangana, India      28157\n5      Pune, Maharashtra, India      26896\n6    Chennai, Tamil Nadu, India      24606\n7                         China      23335\n8        London, United Kingdom      19696\n9                        France      18544\n10                United States      18527\n11   Mumbai, Maharashtra, India      17546\n12                Paris, France      16643\n13                          USA      16215\n14  Bengaluru, Karnataka, India      15676\n15                  Philippines      15263\n16                    Indonesia      14374\n17               United Kingdom      13605\n18                 Delhi, India      13315\n19                    Singapore      13100\n20                       Canada      12756\n21                       Israel      12676\n22                  Netherlands      12304\n23                     Pakistan      12283\n24                       Russia      12051\n25                        Egypt      11572\n26                       Brazil      11389\n27                   London, UK      11321\n28    Ahmedabad, Gujarat, India      11065\n29                         Iran      10740\n30          Toronto, ON, Canada      10736\n31                       Poland      10523\n32            Dhaka, Bangladesh      10474\n33             Bangalore, India      10245\n34      New Delhi, Delhi, India      10206\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. AS, WITH\n**AS** : is function for rename. AS has used in cell above\n\n**WITH .. AS**: AS combined with is a `common table expression`(or `CTE`). `CTE` is temporary table that you return within your query. It help splitting your queries into readable chunk.\n\n    Task 5: - create a temporary table with name time have month column\n            - count the number of month with the name `num_of_each_month`"},{"metadata":{"trusted":true},"cell_type":"code","source":"#     Task 5: - create a temporary table with name time have month column\n#             - count the number of month with the name `num_of_each_month`\nquery_task5 = \"\"\"\n              WITH time AS \n              (\n                  SELECT EXTRACT(MONTH from creation_date) AS month\n                  From `bigquery-public-data.stackoverflow.users`\n                  \n              )\n              SELECT month, COUNT(1) AS num_of_each_month\n              FROM time\n              GROUP BY month\n              ORDER BY num_of_each_month DESC\n              \"\"\"\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config5 = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job5 = client.query(query_task5, job_config=dry_run_config5)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job5.total_bytes_processed))\n\nsafe_config_task5 = bigquery.QueryJobConfig(maximun_bytes_billed = 10*10)\nusers_query_task5_job = client.query(query_task5, job_config = safe_config_task5)\nusers_task5_result = users_query_task5_job.to_dataframe()\nprint(users_task5_result)","execution_count":78,"outputs":[{"output_type":"stream","text":"This query will process 87458360 bytes.\n    month  num_of_each_month\n0      12             787075\n1      11             868823\n2      10             903479\n3       9             826095\n4       8             939167\n5       7             980734\n6       6             924390\n7       5             974051\n8       4             953413\n9       3            1001101\n10      2             881549\n11      1             892418\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# 6. JOIN data\n\n**JOIN**: It help you write a query to create a table that you can fix two coloumns which in two different table together.\n\nThe type of `JOIN`. we are using is called an `INNER JOIN`. That means that a row will only be put in the final output table if the value in the column you are using to combine them shows up in both the tables you are joining.\n\n\n    Task 6: - we going to \"tags\" table\n            - combining tag_name and location with the same id\n            "},{"metadata":{"trusted":true},"cell_type":"code","source":"# change \"tags\" table into dataframe\ntable_tags_ref = data_ref.table(\"tags\") \ntable_tags = client.get_table(table_tags_ref)\ntable_tags_frame = client.list_rows(table_tags, max_results=5).to_dataframe()\nprint(table_tags_frame.shape)\ntable_tags_frame.head()","execution_count":80,"outputs":[{"output_type":"stream","text":"(5, 5)\n","name":"stdout"},{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"      id             tag_name  count  excerpt_post_id  wiki_post_id\n0   8383        prerequisites    256         13267340      13267339\n1   9328  bufferedinputstream    256         13050316      13050315\n2  11688         code-metrics    256          5893530       5893529\n3  15140            switching    256         19226730      19226729\n4  19404        wshttpbinding    256         14740676      14740675","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tag_name</th>\n      <th>count</th>\n      <th>excerpt_post_id</th>\n      <th>wiki_post_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8383</td>\n      <td>prerequisites</td>\n      <td>256</td>\n      <td>13267340</td>\n      <td>13267339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9328</td>\n      <td>bufferedinputstream</td>\n      <td>256</td>\n      <td>13050316</td>\n      <td>13050315</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11688</td>\n      <td>code-metrics</td>\n      <td>256</td>\n      <td>5893530</td>\n      <td>5893529</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>15140</td>\n      <td>switching</td>\n      <td>256</td>\n      <td>19226730</td>\n      <td>19226729</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19404</td>\n      <td>wshttpbinding</td>\n      <td>256</td>\n      <td>14740676</td>\n      <td>14740675</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_task6 = \"\"\"\n                         SELECT t.tag_name AS tag_name, u.location AS location\n                         FROM `bigquery-public-data.stackoverflow.users` AS u\n                         INNER JOIN `bigquery-public-data.stackoverflow.tags` AS t\n                             ON u.id = t.id\n                         GROUP BY t.tag_name, u.location\n                         \"\"\"\n# Create a QueryJobConfig object to estimate size of query without running it\ndry_run_config6 = bigquery.QueryJobConfig(dry_run=True)\n\n# API request - dry run query to estimate costs\ndry_run_query_job6 = client.query(query_task6, job_config=dry_run_config6)\n\nprint(\"This query will process {} bytes.\".format(dry_run_query_job6.total_bytes_processed))\n\nsafe_config_task6 = bigquery.QueryJobConfig(maximun_bytes_billed = 10*10)\nusers_query_task6_job = client.query(query_task6, job_config = safe_config_task6)\nusers_task6_result = users_query_task6_job.to_dataframe()\nprint(users_task6_result)\n","execution_count":91,"outputs":[{"output_type":"stream","text":"This query will process 143178324 bytes.\n               tag_name                location\n0               cmdlets                   Chile\n1                winapi       Vancouver, Canada\n2                 state         Munich, Germany\n3         unordered-map     Leiden, Netherlands\n4                   esb                Michigan\n...                 ...                     ...\n19404     color-palette  London, United Kingdom\n19405  swift-extensions  London, United Kingdom\n19406       openinviter  London, United Kingdom\n19407           jslider  London, United Kingdom\n19408          neteller  London, United Kingdom\n\n[19409 rows x 2 columns]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# That all. GOOD LUCK!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}